\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=3cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyhdr}
\usepackage{seminar}
\usepackage{graphicx}
% \usepackage{subfigure}
\usepackage{float}
\usepackage{hyperref}

\usepackage[round]{natbib}   % omit 'round' option if you prefer square brackets

\usepackage{hhline}
\usepackage{multirow}

\usepackage{mathrsfs}
\usepackage{commath}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{appendix}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\pagestyle{fancy}


%You can add theorem-like environments (e.g. remark, definition, ...) if you want
\newtheorem{theorem}{Theorem}

\title{Learning graph distances} % Replace with your title
% \newcommand{\shorttitle}{\title}
% \shorttitle{Learning graph distances}
\author{Johannes Pitz} % Replace with your name
\institute{\textit{Guided Research: Data Analytics and Machine Learning Group  \protect\\ TUM Department of Informatics}}

\makeatletter
\let\runauthor\@author
\let\runtitle\@title
\makeatother
\lhead{\runauthor}
\rhead{\runtitle}


\begin{document}

\title{Learning graph distances \protect\\ via graph neural networks and node matching}
\maketitle

\begin{abstract}


Computing meaningful distances between graphs is often difficult due to the combinatorial explosion of possible transformations on graphs. Recently researchers started using graph neural networks attempting to use learning methods to replace classical search algorithms. However, these learning methods often have bottlenecks such as fixed size graph embeddings, which prevent them from scaling to larger graphs. We propose to use soft matchings between nodes to overcome this problem. Our novel combination of a classical cost matrix, motivated by bipartite graph matching algorithms, and the modern sinkhorn distance shows state-of-the-art results predicting the ubiquitous graph edit distance. Additionally, we report strong empirical results at graph matching with the same model. Our implementation\footnote{\url{https://gitlab.lrz.de/gdn/graph-distance}} efficiently handles sparse inputs and large real world graphs.

% of pairwise distances between nodes in the form

% However, these learning methods often neglect the

% Graph neural networks suffer bottleneck problems
% We propose to use soft matching between nodes, using a cost matrix, motivated by bipartie graph matching and sinkhorn distance.
% We show empirically that our model improves upon state-of-the-art methods on the task of predicting the graph edit distance
% and demontrate that it can be used for graph matching.
% Our sparsity-aware implementation\footnote{} scales well to large real world graphs.



\end{abstract}

\input{01_introduction.tex}

\input{01b_derivation.tex}

\input{01c_related_work.tex}

\input{02_setup.tex}

\input{03_results.tex}

\input{04_conclusion.tex}

\input{05_outlook.tex}

\newpage

\bibliographystyle{plainnat}
\bibliography{egbib}

% cite    -> Name (year)
% citealp -> Name, year

\newpage

\input{05_appendix.tex}


\end{document}
